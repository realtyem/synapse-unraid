# syntax=docker/dockerfile:1
# Dockerfile to build our forked matrixdotorg/synapse docker images.
#
# Note that it uses features which are only available in BuildKit - see
# https://docs.docker.com/go/buildkit/ for more information.
#
# To build the image, run `docker build` command from the root of the
# synapse repository:
#
#    DOCKER_BUILDKIT=1 docker build -f docker/Dockerfile-unified .
#
# There is an optional PYTHON_VERSION build argument which sets the
# version of python to build against: for example:
#
#    DOCKER_BUILDKIT=1 docker build -f docker/Dockerfile-unified --build-arg PYTHON_VERSION=3.10 .
#

# Irritatingly, there is no blessed guide on how to distribute an application with its
# poetry-managed environment in a docker image. We have opted for
# `poetry export | pip install -r /dev/stdin`, but there are known bugs
# in `poetry export` whose fixes (scheduled for poetry 1.2) have yet to be released.
# In case we get bitten by those bugs in the future, the recommendations here might
# be useful:
#     https://github.com/python-poetry/poetry/discussions/1879#discussioncomment-216865
#     https://stackoverflow.com/questions/53835198/integrating-python-poetry-with-docker?answertab=scoredesc



ARG PYTHON_VERSION=3.9

###
### Stage 0: generate requirements.txt
###
# We hardcode the use of Debian bullseye here because this could change upstream
# and other Dockerfiles used for testing are expecting bullseye.
FROM docker.io/python:${PYTHON_VERSION}-slim-bullseye as requirements

# RUN --mount is specific to buildkit and is documented at
# https://github.com/moby/buildkit/blob/master/frontend/dockerfile/docs/syntax.md#build-mounts-run---mount.
# Here we use it to set up a cache for apt (and below for pip), to improve
# rebuild speeds on slow connections.
RUN \
   --mount=type=cache,target=/var/cache/apt,sharing=locked \
   --mount=type=cache,target=/var/lib/apt,sharing=locked \
    apt-get update -qq && apt-get install -yqq \
      build-essential cargo git libffi-dev libssl-dev \
    && rm -rf /var/lib/apt/lists/*

# We install poetry in its own build stage to avoid its dependencies conflicting with
# synapse's dependencies.
RUN --mount=type=cache,target=/root/.cache/pip \
  pip install --user "poetry==1.2.0"

WORKDIR /synapse

# Copy just what we need to run `poetry export`...
COPY pyproject.toml poetry.lock /synapse/


# If specified, we won't verify the hashes of dependencies.
# This is only needed if the hashes of dependencies cannot be checked for some
# reason, such as when a git repository is used directly as a dependency.
# Specifically, this is currently used during CI workflow testing.
ARG TEST_ONLY_SKIP_DEP_HASH_VERIFICATION

# If specified, we won't use the Poetry lockfile.
# Instead, we'll just install what a regular `pip install` would from PyPI.
# This is also currently used during CI workflow testing.
ARG TEST_ONLY_IGNORE_POETRY_LOCKFILE

# Export the dependencies, but only if we're actually going to use the Poetry lockfile.
# Otherwise, just create an empty requirements file so that the Dockerfile can
# proceed.
RUN if [ -z "$TEST_ONLY_IGNORE_POETRY_LOCKFILE" ]; then \
    /root/.local/bin/poetry export --extras all -o /synapse/requirements.txt ${TEST_ONLY_SKIP_DEP_HASH_VERIFICATION:+--without-hashes}; \
  else \
    touch /synapse/requirements.txt; \
  fi

###
### Stage 1: builder
###
FROM docker.io/python:${PYTHON_VERSION}-slim-bullseye as builder

# install the OS build deps
RUN \
   --mount=type=cache,target=/var/cache/apt,sharing=locked \
   --mount=type=cache,target=/var/lib/apt,sharing=locked \
 apt-get update -qq && apt-get install -yqq \
    build-essential \
    libffi-dev \
    libjpeg-dev \
    libpq-dev \
    libssl-dev \
    libwebp-dev \
    libxml++2.6-dev \
    libxslt1-dev \
    openssl \
    zlib1g-dev \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*


# Install rust and ensure its in the PATH
ENV RUSTUP_HOME=/rust
ENV CARGO_HOME=/cargo
ENV PATH=/cargo/bin:/rust/bin:$PATH
RUN mkdir /rust /cargo

RUN curl -sSf https://sh.rustup.rs | sh -s -- -y --no-modify-path --default-toolchain stable

# To speed up rebuilds, install all of the dependencies before we copy over
# the whole synapse project, so that this layer in the Docker cache can be
# used while you develop on the source
#
# This is aiming at installing the `[tool.poetry.depdendencies]` from pyproject.toml.
COPY --from=requirements /synapse/requirements.txt /synapse/
RUN --mount=type=cache,target=/root/.cache/pip \
  pip install --prefix="/install" --no-deps --no-warn-script-location -r /synapse/requirements.txt

# Copy over the rest of the synapse source code.
COPY synapse /synapse/synapse/
COPY rust /synapse/rust/
# ... and what we need to `pip install`.
COPY pyproject.toml README.rst build_rust.py /synapse/

# Repeat of earlier build argument declaration, as this is a new build stage.
ARG TEST_ONLY_IGNORE_POETRY_LOCKFILE

# Install the synapse package itself.
# If we have populated requirements.txt, we don't install any dependencies
# as we should already have those from the previous `pip install` step.
RUN if [ -z "$TEST_ONLY_IGNORE_POETRY_LOCKFILE" ]; then \
    pip install --prefix="/install" --no-deps --no-warn-script-location /synapse[all]; \
  else \
    pip install --prefix="/install" --no-warn-script-location /synapse[all]; \
  fi

###
### Stage 2: Add-ons
###
# Adding:
# 1. Nginx - for reverse proxy support to avoid exposing a mess of ports
# 2. Redis - for internal replication. This is cleaner and faster than an external redis
# 3. Prometheus - to collect the metrics that Synapse exposes if enabled.
# 3a. Redis metrics exporter
# 3b. Nginx metrics exporter
# ?4. Grafana - Maybe. External is probably better. TODO
# ?5. Postgres - Maybe. Internal server with external persistent storage db files. TODO
# 5a. Postgres metrics exporter
# 5b. Postgres Synapse auto compressor. Add to cron later, after testing.
# ?6. Coturn - Maybe. Notoriously hard to get it right. Lots of ports to expose. TODO
# Not Adding:
# ?1. DNS caching - To many ways to get this wrong. This is better as an external
#     service like pihole or unbound. Getting docker to route through it can be rough.
#
# A base image with nginx and prometheus which we can copy into the
# target image. For repeated rebuilds, this is much faster than apt installing
# each time.

FROM debian:bullseye-slim AS deps_base
    RUN \
       --mount=type=cache,target=/var/cache/apt,sharing=locked \
       --mount=type=cache,target=/var/lib/apt,sharing=locked \
      apt-get update -qq && \
      DEBIAN_FRONTEND=noninteractive apt-get install -yqq --no-install-recommends \
          nginx-light \
          prometheus \
          && rm -rf /var/lib/apt/lists/*

# Similarly, a base to copy the redis server from.
#
# The redis docker image has fewer dynamic libraries than the debian package,
# which makes it much easier to copy (but we need to make sure we use an image
# based on the same debian version as the synapse image, to make sure we get
# the expected version of libc.

# FROM redis:7-bullseye AS redis_base

# The synapse auto compressor is from an image we build. It won't change much
# so there's no reason to not have this pre-compiled and just borrow it.

# FROM realtyem/synapse-tools:latest as tools


###
### Stage #: runtime
###

FROM docker.io/python:${PYTHON_VERSION}-slim-bullseye

LABEL org.opencontainers.image.url='https://matrix.org/docs/projects/server/synapse'
LABEL org.opencontainers.image.documentation='https://github.com/realtyem/synapse/blob/master/docker/README.md'
LABEL org.opencontainers.image.source='https://github.com/realtyem/synapse.git'
LABEL org.opencontainers.image.licenses='Apache-2.0'

RUN \
   --mount=type=cache,target=/var/cache/apt,sharing=locked \
   --mount=type=cache,target=/var/lib/apt,sharing=locked \
  apt-get update -qq && apt-get install -yqq \
    cron \
    curl \
    gosu \
    libevent-core-2.1-7 \
    libevent-extra-2.1-7 \
    libevent-openssl-2.1-7 \
    libevent-pthreads-2.1-7 \
    libhiredis0.14 \
    libjemalloc2 \
    libjpeg62-turbo \
    libmicrohttpd12 \
    libpq5 \
    libssl-dev \
    libwebp6 \
    openssl \
    xmlsec1 \
    && rm -rf /var/lib/apt/lists/*

COPY --from=builder /install /usr/local

# Prepare directories. Do it in one layer
RUN mkdir -p /etc/supervisor/conf.d && \
    mkdir /var/log/nginx /var/lib/nginx && \
    chown www-data /var/lib/nginx && \
    ln -sf /dev/stdout /var/log/nginx/access.log && \
    ln -sf /dev/stderr /var/log/nginx/error.log && \
    mkdir -p /etc/prometheus

# Install supervisord with pip instead of apt, to avoid installing a second
# copy of python.
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install supervisor~=4.2

# Copy over redis and nginx
COPY --from=redis:7-bullseye /usr/local/bin/redis-server /usr/local/bin

COPY --from=deps_base /usr/sbin/nginx /usr/sbin
COPY --from=deps_base /usr/share/nginx /usr/share/nginx
COPY --from=deps_base /usr/lib/nginx /usr/lib/nginx
COPY --from=deps_base /etc/nginx /etc/nginx
RUN rm /etc/nginx/sites-enabled/default

# Copy over Prometheus. Should we bring the website files. It's 10's of MB's
COPY --from=deps_base /usr/bin/prometheus /usr/bin
COPY --from=deps_base /usr/share/prometheus/* /usr/share/prometheus

# Copy in the redis_exporter
# COPY --from=tools /usr/local/bin/redis_exporter /usr/local/bin/redis_exporter
# COPY --from=tools /etc/ssl/certs /etc/ssl/certs

# Copy in the auto state compressor and the redis metrics exporter
# COPY --from=realtyem/synapse-tools:latest /usr/local/bin/synapse_compress_state \
#    /usr/local/bin/synapse_auto_compressor \
#    /usr/local/bin/postgres_exporter \
#    /usr/local/bin/redis_exporter \
#    /usr/local/bin/
# This will simplify the copying of programs and libs. Also will keeps future layers
# from spiraling out of control.
COPY --from=realtyem/synapse-tools:latest /out /

# Copy Synapse worker, nginx and supervisord configuration template files
# The base start up script, used to generate some config files
# The worker configuration start up script. Will start supervisord.
COPY ./docker/start.py ./docker/configure_workers_and_start.py /

# Various config and script templates.
COPY ./docker/conf ./docker/conf-workers /conf/

# Copy a script to prefix log lines with the supervisor program name
COPY ./docker/prefix-log /usr/local/bin/
# Copy over prometheus contrib files, rules and such
COPY ./contrib/prometheus/* /etc/prometheus/

# Expose nginx listener port
EXPOSE 8008/tcp
# Expose the prometheus listener port
EXPOSE 9090/tcp

ENTRYPOINT ["/configure_workers_and_start.py"]

# Replace the healthcheck with one which checks *all* the workers. The script
# is generated by configure_workers_and_start.py.
HEALTHCHECK --start-period=5s --interval=15s --timeout=5s \
    CMD /bin/sh /healthcheck.sh
